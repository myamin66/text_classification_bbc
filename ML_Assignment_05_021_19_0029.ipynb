{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jJ5V-phUlS0n",
        "outputId": "bdcc9acb-ae4f-4b47-ce3c-5315c0663b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLIad7ylMbCt",
        "outputId": "b94c93e2-f832-4999-d3b5-96b185d687d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_base_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/bbc'"
      ],
      "metadata": {
        "id": "v8Tm2qNCiUvG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preparing the training data"
      ],
      "metadata": {
        "id": "geIp8Pgyw_lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from string import digits\n",
        "import string\n",
        "\n",
        "\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "\n",
        "train_dir = os.path.join(new_base_dir, 'train')\n",
        "\n",
        "train_labels = []\n",
        "train_data = []\n",
        "\n",
        "for label_type in ['business', 'entertainment','politics', 'sport', 'tech']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':       \n",
        "            f = open(os.path.join(dir_name, fname),encoding='latin1')     \n",
        "            a = remove_stopwords(f.read()) \n",
        "            a = a.translate(remove_digits) \n",
        "            a = a.translate(str.maketrans('', '', string.punctuation))\n",
        "            train_data.append(a)\n",
        "            f.close()\n",
        "            if label_type == 'business':\n",
        "                train_labels.append(0)\n",
        "            elif label_type == 'entertainment':\n",
        "                train_labels.append(1)\n",
        "            elif label_type == 'politics':\n",
        "                train_labels.append(2)\n",
        "            elif label_type == 'sport':\n",
        "                train_labels.append(3)    \n",
        "            else:\n",
        "                train_labels.append(4)"
      ],
      "metadata": {
        "id": "DvZRV1iEPdJe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2uquREasdHL",
        "outputId": "8c9a8ea2-a2be-4c7c-b4f9-dad7737baedc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1725"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwxMRc7VsoE8",
        "outputId": "6299e750-0d79-434d-ec64-1cc3e8075226"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1725"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[409])\n",
        "print(train_labels[410])\n",
        "print(train_labels[696])\n",
        "print(train_labels[1013])\n",
        "print(train_labels[1424])\n",
        "print(train_labels[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlZasRrSsoM0",
        "outputId": "5c10060e-469d-4464-b187-00cb5dbedf22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGxNWq21soP1",
        "outputId": "c39b5028-05f9-4570-b4f7-5cf8856ee539"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UK economy facing major risks The UK manufacturing sector continue face serious challenges years British Chamber Commerce BCC said The groups quarterly survey companies exports picked months  best levels years The rise came despite exchange rates cited major concern However BCC UK economy faced major risks warned growth set slow It recently forecast economic growth slow   little    Manufacturers domestic sales growth fell slightly quarter survey  firms found Employment manufacturing fell job expectations lowest level year Despite positive news export sector worrying signs manufacturing BCC said These results reinforce concern sectors persistent inability sustain recovery The outlook service sector uncertain despite increase exports orders quarter BCC noted The BCC confidence increased quarter manufacturing service sectors overall failed reach levels start  The reduced threat rate increases contributed improved confidence said The Bank England raised rates times November  August year But rates kept hold amid signs falling consumer confidence slowdown output The pressure costs margins relentless increase regulations threat higher taxes remain problems BCC director general David Frost said While consumer spending set decelerate significantly  months unlikely investment exports rise sufficiently strongly pick slack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSUlqfNz0Q_U",
        "outputId": "21dc6097-8abe-4542-8ee4-9bdf1ac14e53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenization of training data"
      ],
      "metadata": {
        "id": "oNYXb3JR3bn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100  # We will cut reviews after 100 words\n",
        "training_samples = 1380  # We will be training on 1380 samples\n",
        "validation_samples = 345  # We will be validating on 345 samples\n",
        "max_words = 10000  # We will only consider the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "sequences = tokenizer.texts_to_sequences(train_data)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttB7Ow-csoS5",
        "outputId": "01db1064-f859-4bb4-98f8-993b107ac697"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28180 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "labels = np.asarray(train_labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD6Te5_t8QBr",
        "outputId": "fdcfc0fc-deb5-42ba-bd0e-4c01c0b08690"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data tensor: (1725, 100)\n",
            "Shape of label tensor: (1725,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48CJhwdL8nSy",
        "outputId": "d020d7dc-f04a-47f6-a90f-1f739b47dc25"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 634, 2709, 1909, 1353, 5728,    2,  918,  581, 6760,  961, 2916,\n",
              "       4974, 6761, 4671,  938,    1, 2106,   93,  634, 4672,  156,  305,\n",
              "        999, 1327,  354, 5728, 3385,    1, 5728,  860,  755,  354, 1353,\n",
              "         93, 2916, 1059,  439,  982,  763,  121,    1, 1910,  704,  320,\n",
              "       1707, 5320, 1480,  860,    2,    1,  119,   38,  873,  378,  188,\n",
              "        392,  962,   10,    8,  378, 1014,  385, 1574, 1909, 1246,  365,\n",
              "        860, 2107, 1205,    1,  568,  325, 3656, 7405,  305, 2917,  704,\n",
              "        453,  764,  523,  282, 5728,  115,  165,  248, 2530,    2,  724,\n",
              "        365,  211,   40, 3844,   69, 1171,  336,  999,  173, 7406, 2213,\n",
              "       1708], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUEUcIvz8qIw",
        "outputId": "ee29d030-5c26-4d69-f621-90be002041fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'said': 2,\n",
              " 'i': 3,\n",
              " 'mr': 4,\n",
              " 'it': 5,\n",
              " 'new': 6,\n",
              " 'people': 7,\n",
              " 'but': 8,\n",
              " 'us': 9,\n",
              " 'year': 10,\n",
              " 'he': 11,\n",
              " 'years': 12,\n",
              " 'a': 13,\n",
              " 'in': 14,\n",
              " 'time': 15,\n",
              " 'we': 16,\n",
              " 'government': 17,\n",
              " 'world': 18,\n",
              " 'm': 19,\n",
              " 'told': 20,\n",
              " 'its': 21,\n",
              " 'best': 22,\n",
              " 'uk': 23,\n",
              " 'game': 24,\n",
              " 'music': 25,\n",
              " 'like': 26,\n",
              " 'bbc': 27,\n",
              " 'added': 28,\n",
              " 'number': 29,\n",
              " 'way': 30,\n",
              " 'this': 31,\n",
              " 'says': 32,\n",
              " 'market': 33,\n",
              " 'good': 34,\n",
              " 'games': 35,\n",
              " 'home': 36,\n",
              " 'and': 37,\n",
              " 'england': 38,\n",
              " 'bn': 39,\n",
              " 'set': 40,\n",
              " 'company': 41,\n",
              " 'there': 42,\n",
              " 'think': 43,\n",
              " 'going': 44,\n",
              " 'work': 45,\n",
              " 'film': 46,\n",
              " 'â£m': 47,\n",
              " 'use': 48,\n",
              " 'firm': 49,\n",
              " 'million': 50,\n",
              " 'they': 51,\n",
              " 'want': 52,\n",
              " 'week': 53,\n",
              " 'win': 54,\n",
              " 'that': 55,\n",
              " 'players': 56,\n",
              " 'public': 57,\n",
              " 'labour': 58,\n",
              " 'sales': 59,\n",
              " 'won': 60,\n",
              " 'play': 61,\n",
              " 'european': 62,\n",
              " 'news': 63,\n",
              " 'minister': 64,\n",
              " 'however': 65,\n",
              " 'technology': 66,\n",
              " 'blair': 67,\n",
              " 'expected': 68,\n",
              " 'months': 69,\n",
              " 'second': 70,\n",
              " 'group': 71,\n",
              " 'end': 72,\n",
              " 'if': 73,\n",
              " 'election': 74,\n",
              " 'british': 75,\n",
              " 'growth': 76,\n",
              " 'come': 77,\n",
              " 's': 78,\n",
              " 'deal': 79,\n",
              " 'plans': 80,\n",
              " 'wales': 81,\n",
              " 'party': 82,\n",
              " 'chief': 83,\n",
              " 'record': 84,\n",
              " 'dont': 85,\n",
              " 'firms': 86,\n",
              " 'need': 87,\n",
              " 'help': 88,\n",
              " 'economy': 89,\n",
              " 'international': 90,\n",
              " 'tv': 91,\n",
              " 'right': 92,\n",
              " 'service': 93,\n",
              " 'companies': 94,\n",
              " 'place': 95,\n",
              " 'london': 96,\n",
              " 'club': 97,\n",
              " 'report': 98,\n",
              " 'money': 99,\n",
              " 'mobile': 100,\n",
              " 'team': 101,\n",
              " 'industry': 102,\n",
              " 'users': 103,\n",
              " 'according': 104,\n",
              " 'country': 105,\n",
              " 'including': 106,\n",
              " 'â£': 107,\n",
              " 'great': 108,\n",
              " 'economic': 109,\n",
              " 'on': 110,\n",
              " 'services': 111,\n",
              " 'digital': 112,\n",
              " 'business': 113,\n",
              " 'got': 114,\n",
              " 'director': 115,\n",
              " 'future': 116,\n",
              " 'spokesman': 117,\n",
              " 'big': 118,\n",
              " 'bank': 119,\n",
              " 'day': 120,\n",
              " 'start': 121,\n",
              " 'hit': 122,\n",
              " 'net': 123,\n",
              " 'united': 124,\n",
              " 'came': 125,\n",
              " 'europe': 126,\n",
              " 'phone': 127,\n",
              " 'know': 128,\n",
              " 'one': 129,\n",
              " 'decision': 130,\n",
              " 'online': 131,\n",
              " 'law': 132,\n",
              " 'ireland': 133,\n",
              " 'im': 134,\n",
              " 'high': 135,\n",
              " 'information': 136,\n",
              " 'took': 137,\n",
              " 'nations': 138,\n",
              " 'oil': 139,\n",
              " 'month': 140,\n",
              " 'better': 141,\n",
              " 'video': 142,\n",
              " 'software': 143,\n",
              " 'figures': 144,\n",
              " 'tax': 145,\n",
              " 'as': 146,\n",
              " 'action': 147,\n",
              " 'far': 148,\n",
              " 'real': 149,\n",
              " 'national': 150,\n",
              " 'court': 151,\n",
              " 'offer': 152,\n",
              " 'brown': 153,\n",
              " 'seen': 154,\n",
              " 'life': 155,\n",
              " 'despite': 156,\n",
              " 'january': 157,\n",
              " 'final': 158,\n",
              " 'data': 159,\n",
              " 'radio': 160,\n",
              " 'given': 161,\n",
              " 'likely': 162,\n",
              " 'president': 163,\n",
              " 'away': 164,\n",
              " 'general': 165,\n",
              " 'executive': 166,\n",
              " 'saying': 167,\n",
              " 'long': 168,\n",
              " 'ms': 169,\n",
              " 'france': 170,\n",
              " 'prime': 171,\n",
              " 'look': 172,\n",
              " 'rise': 173,\n",
              " 'lot': 174,\n",
              " 'research': 175,\n",
              " 'prices': 176,\n",
              " 'office': 177,\n",
              " 'britain': 178,\n",
              " 'media': 179,\n",
              " 'case': 180,\n",
              " 'countries': 181,\n",
              " 'awards': 182,\n",
              " 'campaign': 183,\n",
              " 'called': 184,\n",
              " 'able': 185,\n",
              " 'police': 186,\n",
              " 'security': 187,\n",
              " 'times': 188,\n",
              " 'shares': 189,\n",
              " 'â£bn': 190,\n",
              " 'december': 191,\n",
              " 'internet': 192,\n",
              " 'analysts': 193,\n",
              " 'recent': 194,\n",
              " 'cup': 195,\n",
              " 'important': 196,\n",
              " 'following': 197,\n",
              " 'earlier': 198,\n",
              " 'past': 199,\n",
              " 'state': 200,\n",
              " 'yearold': 201,\n",
              " 'days': 202,\n",
              " 'all': 203,\n",
              " 'award': 204,\n",
              " 'howard': 205,\n",
              " 'half': 206,\n",
              " 'strong': 207,\n",
              " 'foreign': 208,\n",
              " 'went': 209,\n",
              " 'secretary': 210,\n",
              " 'spending': 211,\n",
              " 'player': 212,\n",
              " 'current': 213,\n",
              " 'lost': 214,\n",
              " 'later': 215,\n",
              " 'cut': 216,\n",
              " 'taking': 217,\n",
              " 'john': 218,\n",
              " 'early': 219,\n",
              " 'legal': 220,\n",
              " 'making': 221,\n",
              " 'she': 222,\n",
              " 'for': 223,\n",
              " 'you': 224,\n",
              " 'return': 225,\n",
              " 'season': 226,\n",
              " 'biggest': 227,\n",
              " 'financial': 228,\n",
              " 'house': 229,\n",
              " 'thought': 230,\n",
              " 'left': 231,\n",
              " 'change': 232,\n",
              " 'sale': 233,\n",
              " 'believe': 234,\n",
              " 'coach': 235,\n",
              " 'looking': 236,\n",
              " 'south': 237,\n",
              " 'star': 238,\n",
              " 'try': 239,\n",
              " 'rights': 240,\n",
              " 'currently': 241,\n",
              " 'major': 242,\n",
              " 'support': 243,\n",
              " 'meeting': 244,\n",
              " 'key': 245,\n",
              " 'hard': 246,\n",
              " 'scotland': 247,\n",
              " 'david': 248,\n",
              " 'control': 249,\n",
              " 'man': 250,\n",
              " 'little': 251,\n",
              " 'ahead': 252,\n",
              " 'pay': 253,\n",
              " 'personal': 254,\n",
              " 'rugby': 255,\n",
              " 'latest': 256,\n",
              " 'now': 257,\n",
              " 'played': 258,\n",
              " 'chance': 259,\n",
              " 'weeks': 260,\n",
              " 'lord': 261,\n",
              " 'run': 262,\n",
              " 'leader': 263,\n",
              " 'having': 264,\n",
              " 'working': 265,\n",
              " 'manager': 266,\n",
              " 'different': 267,\n",
              " 'mark': 268,\n",
              " 'league': 269,\n",
              " 'minutes': 270,\n",
              " 'face': 271,\n",
              " 'series': 272,\n",
              " 'taken': 273,\n",
              " 'programme': 274,\n",
              " 'michael': 275,\n",
              " 'playing': 276,\n",
              " 'access': 277,\n",
              " 'chelsea': 278,\n",
              " 'local': 279,\n",
              " 'line': 280,\n",
              " 'held': 281,\n",
              " 'problems': 282,\n",
              " 'search': 283,\n",
              " 'announced': 284,\n",
              " 'band': 285,\n",
              " 'issue': 286,\n",
              " 'eu': 287,\n",
              " 'cost': 288,\n",
              " 'include': 289,\n",
              " 'them': 290,\n",
              " 'bid': 291,\n",
              " 'things': 292,\n",
              " 'share': 293,\n",
              " 'g': 294,\n",
              " 'album': 295,\n",
              " 'job': 296,\n",
              " 'with': 297,\n",
              " 'broadband': 298,\n",
              " 'fans': 299,\n",
              " 'dollar': 300,\n",
              " 'role': 301,\n",
              " 'yukos': 302,\n",
              " 'claims': 303,\n",
              " 'released': 304,\n",
              " 'increase': 305,\n",
              " 'february': 306,\n",
              " 'members': 307,\n",
              " 'jobs': 308,\n",
              " 'sold': 309,\n",
              " 'march': 310,\n",
              " 'six': 311,\n",
              " 'at': 312,\n",
              " 'performance': 313,\n",
              " 'ministers': 314,\n",
              " 'warned': 315,\n",
              " 'means': 316,\n",
              " 'problem': 317,\n",
              " 'needed': 318,\n",
              " 'to': 319,\n",
              " 'rate': 320,\n",
              " 'price': 321,\n",
              " 'website': 322,\n",
              " 'clear': 323,\n",
              " 'political': 324,\n",
              " 'costs': 325,\n",
              " 'demand': 326,\n",
              " 'football': 327,\n",
              " 'act': 328,\n",
              " 'children': 329,\n",
              " 'statement': 330,\n",
              " 'trade': 331,\n",
              " 'lead': 332,\n",
              " 'network': 333,\n",
              " 'tuesday': 334,\n",
              " 'continue': 335,\n",
              " 'investment': 336,\n",
              " 'result': 337,\n",
              " 'match': 338,\n",
              " 'possible': 339,\n",
              " 'wednesday': 340,\n",
              " 'th': 341,\n",
              " 'mps': 342,\n",
              " 'ago': 343,\n",
              " 'sunday': 344,\n",
              " 'title': 345,\n",
              " 'injury': 346,\n",
              " 'getting': 347,\n",
              " 'thing': 348,\n",
              " 'open': 349,\n",
              " 'huge': 350,\n",
              " 'power': 351,\n",
              " 'song': 352,\n",
              " 'tory': 353,\n",
              " 'quarter': 354,\n",
              " 'worlds': 355,\n",
              " 'some': 356,\n",
              " 'allow': 357,\n",
              " 'point': 358,\n",
              " 'monday': 359,\n",
              " 'policy': 360,\n",
              " 'microsoft': 361,\n",
              " 'race': 362,\n",
              " 'available': 363,\n",
              " 'level': 364,\n",
              " 'consumer': 365,\n",
              " 'thats': 366,\n",
              " 'phones': 367,\n",
              " 'free': 368,\n",
              " 'plan': 369,\n",
              " 'global': 370,\n",
              " 'total': 371,\n",
              " 'close': 372,\n",
              " 'chairman': 373,\n",
              " 'committee': 374,\n",
              " 'site': 375,\n",
              " 'customers': 376,\n",
              " 'so': 377,\n",
              " 'rates': 378,\n",
              " 'sites': 379,\n",
              " 'union': 380,\n",
              " 'chancellor': 381,\n",
              " 'tony': 382,\n",
              " 'success': 383,\n",
              " 'sport': 384,\n",
              " 'hold': 385,\n",
              " 'reports': 386,\n",
              " 'wanted': 387,\n",
              " 'sir': 388,\n",
              " 'content': 389,\n",
              " 'forward': 390,\n",
              " 'issues': 391,\n",
              " 'november': 392,\n",
              " 'young': 393,\n",
              " 'recently': 394,\n",
              " 'films': 395,\n",
              " 'what': 396,\n",
              " 'centre': 397,\n",
              " 'cash': 398,\n",
              " 'main': 399,\n",
              " 'coming': 400,\n",
              " 'christmas': 401,\n",
              " 'victory': 402,\n",
              " 'evidence': 403,\n",
              " 'agreed': 404,\n",
              " 'web': 405,\n",
              " 'competition': 406,\n",
              " 'stock': 407,\n",
              " 'jones': 408,\n",
              " 'his': 409,\n",
              " 'running': 410,\n",
              " 'tories': 411,\n",
              " 'trying': 412,\n",
              " 'aid': 413,\n",
              " 'war': 414,\n",
              " 'head': 415,\n",
              " 'williams': 416,\n",
              " 'list': 417,\n",
              " 'boss': 418,\n",
              " 'asked': 419,\n",
              " 'human': 420,\n",
              " 'live': 421,\n",
              " 'well': 422,\n",
              " 'form': 423,\n",
              " 'winning': 424,\n",
              " 'trial': 425,\n",
              " 'goal': 426,\n",
              " 'other': 427,\n",
              " 'development': 428,\n",
              " 'city': 429,\n",
              " 'based': 430,\n",
              " 'liverpool': 431,\n",
              " 'friday': 432,\n",
              " 'euros': 433,\n",
              " 'him': 434,\n",
              " 'saw': 435,\n",
              " 'irish': 436,\n",
              " 'reported': 437,\n",
              " 'more': 438,\n",
              " 'failed': 439,\n",
              " 'shows': 440,\n",
              " 'showed': 441,\n",
              " 'late': 442,\n",
              " 'china': 443,\n",
              " 'popular': 444,\n",
              " 'out': 445,\n",
              " 'wants': 446,\n",
              " 'single': 447,\n",
              " 'health': 448,\n",
              " 'olympic': 449,\n",
              " 'comes': 450,\n",
              " 'low': 451,\n",
              " 'book': 452,\n",
              " 'higher': 453,\n",
              " 'september': 454,\n",
              " 'production': 455,\n",
              " 'led': 456,\n",
              " 'budget': 457,\n",
              " 'when': 458,\n",
              " 'small': 459,\n",
              " 'cards': 460,\n",
              " 'manchester': 461,\n",
              " 'board': 462,\n",
              " 'difficult': 463,\n",
              " 'email': 464,\n",
              " 'commission': 465,\n",
              " 'council': 466,\n",
              " 'arsenal': 467,\n",
              " 'annual': 468,\n",
              " 'rose': 469,\n",
              " 'previous': 470,\n",
              " 'fact': 471,\n",
              " 'summer': 472,\n",
              " 'test': 473,\n",
              " 'not': 474,\n",
              " 'buy': 475,\n",
              " 'consumers': 476,\n",
              " 'instead': 477,\n",
              " 'vote': 478,\n",
              " 'up': 479,\n",
              " 'profits': 480,\n",
              " 'american': 481,\n",
              " 'japan': 482,\n",
              " 'feel': 483,\n",
              " 'bill': 484,\n",
              " 'saturday': 485,\n",
              " 'show': 486,\n",
              " 'career': 487,\n",
              " 'squad': 488,\n",
              " 'thursday': 489,\n",
              " 'points': 490,\n",
              " 'version': 491,\n",
              " 'project': 492,\n",
              " 'v': 493,\n",
              " 'scottish': 494,\n",
              " 'pc': 495,\n",
              " 'hope': 496,\n",
              " 'fall': 497,\n",
              " 'italy': 498,\n",
              " 'release': 499,\n",
              " 'mean': 500,\n",
              " 'york': 501,\n",
              " 'governments': 502,\n",
              " 'paul': 503,\n",
              " 'october': 504,\n",
              " 'russian': 505,\n",
              " 'changes': 506,\n",
              " 'launched': 507,\n",
              " 'ensure': 508,\n",
              " 'men': 509,\n",
              " 'actor': 510,\n",
              " 'devices': 511,\n",
              " 'fell': 512,\n",
              " 'giant': 513,\n",
              " 'rules': 514,\n",
              " 'received': 515,\n",
              " 'order': 516,\n",
              " 'africa': 517,\n",
              " 'prize': 518,\n",
              " 'education': 519,\n",
              " 'parties': 520,\n",
              " 'stop': 521,\n",
              " 'sure': 522,\n",
              " 'remain': 523,\n",
              " 'family': 524,\n",
              " 'sent': 525,\n",
              " 'television': 526,\n",
              " 'networks': 527,\n",
              " 'official': 528,\n",
              " 'iraq': 529,\n",
              " 'boost': 530,\n",
              " 'last': 531,\n",
              " 'groups': 532,\n",
              " 'exchange': 533,\n",
              " 'countrys': 534,\n",
              " 'involved': 535,\n",
              " 'no': 536,\n",
              " 'tour': 537,\n",
              " 'apple': 538,\n",
              " 'leading': 539,\n",
              " 'denied': 540,\n",
              " 'may': 541,\n",
              " 'debt': 542,\n",
              " 'idea': 543,\n",
              " 'robinson': 544,\n",
              " 'ball': 545,\n",
              " 'an': 546,\n",
              " 'value': 547,\n",
              " 'meet': 548,\n",
              " 'talks': 549,\n",
              " 'senior': 550,\n",
              " 'break': 551,\n",
              " 'appeal': 552,\n",
              " 'age': 553,\n",
              " 'let': 554,\n",
              " 'mp': 555,\n",
              " 'helped': 556,\n",
              " 'accused': 557,\n",
              " 'claimed': 558,\n",
              " 'turn': 559,\n",
              " 'were': 560,\n",
              " 'old': 561,\n",
              " 'chart': 562,\n",
              " 'drugs': 563,\n",
              " 'claim': 564,\n",
              " 'launch': 565,\n",
              " 'id': 566,\n",
              " 'liberal': 567,\n",
              " 'pressure': 568,\n",
              " 'dr': 569,\n",
              " 'french': 570,\n",
              " 'believes': 571,\n",
              " 'potential': 572,\n",
              " 'growing': 573,\n",
              " 'charles': 574,\n",
              " 'hopes': 575,\n",
              " 'calls': 576,\n",
              " 'black': 577,\n",
              " 'position': 578,\n",
              " 'association': 579,\n",
              " 'attacks': 580,\n",
              " 'results': 581,\n",
              " 'similar': 582,\n",
              " 'independent': 583,\n",
              " 'car': 584,\n",
              " 'choice': 585,\n",
              " 'needs': 586,\n",
              " 'proposals': 587,\n",
              " 'large': 588,\n",
              " 'today': 589,\n",
              " 'started': 590,\n",
              " 'special': 591,\n",
              " 'ban': 592,\n",
              " 'charge': 593,\n",
              " 'rock': 594,\n",
              " 'ive': 595,\n",
              " 'products': 596,\n",
              " 'press': 597,\n",
              " 'known': 598,\n",
              " 'force': 599,\n",
              " 'west': 600,\n",
              " 'school': 601,\n",
              " 'training': 602,\n",
              " 'charges': 603,\n",
              " 'provide': 604,\n",
              " 'included': 605,\n",
              " 'community': 606,\n",
              " 'private': 607,\n",
              " 'gaming': 608,\n",
              " 'street': 609,\n",
              " 'many': 610,\n",
              " 'areas': 611,\n",
              " 'singer': 612,\n",
              " 'investors': 613,\n",
              " 'admitted': 614,\n",
              " 'comments': 615,\n",
              " 'simply': 616,\n",
              " 'makes': 617,\n",
              " 'banks': 618,\n",
              " 'create': 619,\n",
              " 'didnt': 620,\n",
              " 'india': 621,\n",
              " 'situation': 622,\n",
              " 'stage': 623,\n",
              " 'happy': 624,\n",
              " 'hes': 625,\n",
              " 'beat': 626,\n",
              " 'box': 627,\n",
              " 'champions': 628,\n",
              " 'workers': 629,\n",
              " 'german': 630,\n",
              " 'weekend': 631,\n",
              " 'cuts': 632,\n",
              " 'theres': 633,\n",
              " 'sector': 634,\n",
              " 'survey': 635,\n",
              " 'target': 636,\n",
              " 'agency': 637,\n",
              " 'named': 638,\n",
              " 'short': 639,\n",
              " 'drive': 640,\n",
              " 'range': 641,\n",
              " 'laws': 642,\n",
              " 'date': 643,\n",
              " 'conference': 644,\n",
              " 'lib': 645,\n",
              " 'by': 646,\n",
              " 'officials': 647,\n",
              " 'term': 648,\n",
              " 'fraud': 649,\n",
              " 'view': 650,\n",
              " 'bring': 651,\n",
              " 'university': 652,\n",
              " 'history': 653,\n",
              " 'course': 654,\n",
              " 'immigration': 655,\n",
              " 'ukip': 656,\n",
              " 'fourth': 657,\n",
              " 'bad': 658,\n",
              " 'martin': 659,\n",
              " 'soon': 660,\n",
              " 'me': 661,\n",
              " 'of': 662,\n",
              " 'moment': 663,\n",
              " 'champion': 664,\n",
              " 'meanwhile': 665,\n",
              " 'markets': 666,\n",
              " 'concerns': 667,\n",
              " 'johnson': 668,\n",
              " 'system': 669,\n",
              " 'opportunity': 670,\n",
              " 'fight': 671,\n",
              " 'particularly': 672,\n",
              " 'seven': 673,\n",
              " 'night': 674,\n",
              " 'madrid': 675,\n",
              " 'event': 676,\n",
              " 'women': 677,\n",
              " 'athens': 678,\n",
              " 'paid': 679,\n",
              " 'authorities': 680,\n",
              " 'department': 681,\n",
              " 'bush': 682,\n",
              " 'impact': 683,\n",
              " 'fund': 684,\n",
              " 'outside': 685,\n",
              " 'takes': 686,\n",
              " 'forced': 687,\n",
              " 'standard': 688,\n",
              " 'wrong': 689,\n",
              " 'bit': 690,\n",
              " 'numbers': 691,\n",
              " 'average': 692,\n",
              " 'defence': 693,\n",
              " 'spent': 694,\n",
              " 'cant': 695,\n",
              " 'confirmed': 696,\n",
              " 'stars': 697,\n",
              " 'attack': 698,\n",
              " 'websites': 699,\n",
              " 'card': 700,\n",
              " 'body': 701,\n",
              " 'premiership': 702,\n",
              " 'love': 703,\n",
              " 'threat': 704,\n",
              " 'june': 705,\n",
              " 'decided': 706,\n",
              " 'civil': 707,\n",
              " 'bankruptcy': 708,\n",
              " 'account': 709,\n",
              " 'britains': 710,\n",
              " 'gave': 711,\n",
              " 'host': 712,\n",
              " 'stand': 713,\n",
              " 'area': 714,\n",
              " 'largest': 715,\n",
              " 'opening': 716,\n",
              " 'hours': 717,\n",
              " 'process': 718,\n",
              " 'states': 719,\n",
              " 'newspaper': 720,\n",
              " 'commons': 721,\n",
              " 'movie': 722,\n",
              " 'dvd': 723,\n",
              " 'while': 724,\n",
              " 'staff': 725,\n",
              " 'parliament': 726,\n",
              " 'poor': 727,\n",
              " 'james': 728,\n",
              " 'technologies': 729,\n",
              " 'turned': 730,\n",
              " 'shot': 731,\n",
              " 'download': 732,\n",
              " 'analyst': 733,\n",
              " 'google': 734,\n",
              " 'gold': 735,\n",
              " 'raise': 736,\n",
              " 'gordon': 737,\n",
              " 'virus': 738,\n",
              " 'schools': 739,\n",
              " 'sony': 740,\n",
              " 'brought': 741,\n",
              " 'sell': 742,\n",
              " 'credit': 743,\n",
              " 'step': 744,\n",
              " 'track': 745,\n",
              " 'reached': 746,\n",
              " 'member': 747,\n",
              " 'gone': 748,\n",
              " 'smith': 749,\n",
              " 'concerned': 750,\n",
              " 'systems': 751,\n",
              " 'bt': 752,\n",
              " 'missed': 753,\n",
              " 'captain': 754,\n",
              " 'increased': 755,\n",
              " 'signed': 756,\n",
              " 'revealed': 757,\n",
              " 'extra': 758,\n",
              " 'challenge': 759,\n",
              " 'society': 760,\n",
              " 'shown': 761,\n",
              " 'experience': 762,\n",
              " 'levels': 763,\n",
              " 'taxes': 764,\n",
              " 'remains': 765,\n",
              " 'leave': 766,\n",
              " 'stay': 767,\n",
              " 'april': 768,\n",
              " 'insisted': 769,\n",
              " 'ways': 770,\n",
              " 'windows': 771,\n",
              " 'songs': 772,\n",
              " 'air': 773,\n",
              " 'unit': 774,\n",
              " 'management': 775,\n",
              " 'double': 776,\n",
              " 'created': 777,\n",
              " 'bought': 778,\n",
              " 'battle': 779,\n",
              " 'energy': 780,\n",
              " 'lower': 781,\n",
              " 'widely': 782,\n",
              " 'white': 783,\n",
              " 'lives': 784,\n",
              " 'newcastle': 785,\n",
              " 'campbell': 786,\n",
              " 'cases': 787,\n",
              " 'looks': 788,\n",
              " 'winners': 789,\n",
              " 'finance': 790,\n",
              " 'focus': 791,\n",
              " 'tsunami': 792,\n",
              " 'response': 793,\n",
              " 'period': 794,\n",
              " 'critics': 795,\n",
              " 'offered': 796,\n",
              " 'do': 797,\n",
              " 'longer': 798,\n",
              " 'spend': 799,\n",
              " 'after': 800,\n",
              " 'lords': 801,\n",
              " 'images': 802,\n",
              " 'cabinet': 803,\n",
              " 'agreement': 804,\n",
              " 'looked': 805,\n",
              " 'robert': 806,\n",
              " 'files': 807,\n",
              " 'easy': 808,\n",
              " 'messages': 809,\n",
              " 'grand': 810,\n",
              " 'd': 811,\n",
              " 'domestic': 812,\n",
              " 'positive': 813,\n",
              " 'north': 814,\n",
              " 'contract': 815,\n",
              " 'argued': 816,\n",
              " 'met': 817,\n",
              " 'scheme': 818,\n",
              " 'speech': 819,\n",
              " 'weve': 820,\n",
              " 'audience': 821,\n",
              " 'zealand': 822,\n",
              " 'kilroysilk': 823,\n",
              " 'although': 824,\n",
              " 'russia': 825,\n",
              " 'original': 826,\n",
              " 'followed': 827,\n",
              " 'terms': 828,\n",
              " 'details': 829,\n",
              " 'too': 830,\n",
              " 'worked': 831,\n",
              " 'my': 832,\n",
              " 'both': 833,\n",
              " 'clubs': 834,\n",
              " 'euro': 835,\n",
              " 'majority': 836,\n",
              " 'rest': 837,\n",
              " 'believed': 838,\n",
              " 'example': 839,\n",
              " 'mike': 840,\n",
              " 'uks': 841,\n",
              " 'message': 842,\n",
              " 'seconds': 843,\n",
              " 'again': 844,\n",
              " 'artists': 845,\n",
              " 'organisation': 846,\n",
              " 'previously': 847,\n",
              " 'worth': 848,\n",
              " 'compared': 849,\n",
              " 'deutsche': 850,\n",
              " 'fear': 851,\n",
              " 'program': 852,\n",
              " 'illegal': 853,\n",
              " 'individual': 854,\n",
              " 'particular': 855,\n",
              " 'story': 856,\n",
              " 'road': 857,\n",
              " 'voters': 858,\n",
              " 'comedy': 859,\n",
              " 'confidence': 860,\n",
              " 'central': 861,\n",
              " 'america': 862,\n",
              " 'build': 863,\n",
              " 'keen': 864,\n",
              " 'andy': 865,\n",
              " 'alan': 866,\n",
              " 'winner': 867,\n",
              " 'quality': 868,\n",
              " 'debate': 869,\n",
              " 'pop': 870,\n",
              " 'students': 871,\n",
              " 'indoor': 872,\n",
              " 'raised': 873,\n",
              " 'federal': 874,\n",
              " 'p': 875,\n",
              " 'allowed': 876,\n",
              " 'field': 877,\n",
              " 'accounts': 878,\n",
              " 'giving': 879,\n",
              " 'talk': 880,\n",
              " 'criminal': 881,\n",
              " 'east': 882,\n",
              " 'pcs': 883,\n",
              " 'debut': 884,\n",
              " 'approach': 885,\n",
              " 'labours': 886,\n",
              " 'matter': 887,\n",
              " 'english': 888,\n",
              " 'tough': 889,\n",
              " 'designed': 890,\n",
              " 'death': 891,\n",
              " 'sides': 892,\n",
              " 'figure': 893,\n",
              " 'ferguson': 894,\n",
              " 'crime': 895,\n",
              " 'before': 896,\n",
              " 'attempt': 897,\n",
              " 'minute': 898,\n",
              " 'conservative': 899,\n",
              " 'cross': 900,\n",
              " 'ceremony': 901,\n",
              " 'penalty': 902,\n",
              " 'watch': 903,\n",
              " 'blunkett': 904,\n",
              " 'risk': 905,\n",
              " 'significant': 906,\n",
              " 'ability': 907,\n",
              " 'probably': 908,\n",
              " 'effort': 909,\n",
              " 'speed': 910,\n",
              " 'confident': 911,\n",
              " 'richard': 912,\n",
              " 'social': 913,\n",
              " 'parents': 914,\n",
              " 'entertainment': 915,\n",
              " 'is': 916,\n",
              " 'park': 917,\n",
              " 'these': 918,\n",
              " 'actually': 919,\n",
              " 'moved': 920,\n",
              " 'dropped': 921,\n",
              " 'j': 922,\n",
              " 'light': 923,\n",
              " 'protection': 924,\n",
              " 'computers': 925,\n",
              " 'viewers': 926,\n",
              " 'profit': 927,\n",
              " 'trading': 928,\n",
              " 'began': 929,\n",
              " 'especially': 930,\n",
              " 'millions': 931,\n",
              " 'titles': 932,\n",
              " 'our': 933,\n",
              " 'welsh': 934,\n",
              " 'described': 935,\n",
              " 'poll': 936,\n",
              " 'asylum': 937,\n",
              " 'recovery': 938,\n",
              " 'nearly': 939,\n",
              " 'rival': 940,\n",
              " 'planning': 941,\n",
              " 'stake': 942,\n",
              " 'massive': 943,\n",
              " 'germany': 944,\n",
              " 'decisions': 945,\n",
              " 'japanese': 946,\n",
              " 'hand': 947,\n",
              " 'pair': 948,\n",
              " 'generation': 949,\n",
              " 'chinese': 950,\n",
              " 'favourite': 951,\n",
              " 'here': 952,\n",
              " 'politics': 953,\n",
              " 'actress': 954,\n",
              " 'portable': 955,\n",
              " 'speculation': 956,\n",
              " 'rising': 957,\n",
              " 'near': 958,\n",
              " 'controversial': 959,\n",
              " 'person': 960,\n",
              " 'concern': 961,\n",
              " 'august': 962,\n",
              " 'ask': 963,\n",
              " 'question': 964,\n",
              " 'affected': 965,\n",
              " 'changed': 966,\n",
              " 'suggested': 967,\n",
              " 'guilty': 968,\n",
              " 'disaster': 969,\n",
              " 'down': 970,\n",
              " 'thousands': 971,\n",
              " 'row': 972,\n",
              " 'clarke': 973,\n",
              " 'aimed': 974,\n",
              " 'rule': 975,\n",
              " 'certainly': 976,\n",
              " 'experts': 977,\n",
              " 'lions': 978,\n",
              " 'machines': 979,\n",
              " 'musical': 980,\n",
              " 'machine': 981,\n",
              " 'reach': 982,\n",
              " 'shareholders': 983,\n",
              " 'adding': 984,\n",
              " 'indian': 985,\n",
              " 'stadium': 986,\n",
              " 'closed': 987,\n",
              " 'effect': 988,\n",
              " 'ready': 989,\n",
              " 'australia': 990,\n",
              " 'judge': 991,\n",
              " 'care': 992,\n",
              " 'appear': 993,\n",
              " 'leicester': 994,\n",
              " 'steve': 995,\n",
              " 'nominations': 996,\n",
              " 'kelly': 997,\n",
              " 'hunting': 998,\n",
              " 'exports': 999,\n",
              " 'thomas': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data into a training set and a validation set"
      ],
      "metadata": {
        "id": "iaGCG_7f3j0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a validation set\n",
        "# But first, shuffle the data, since we started from data\n",
        "# where sample are ordered (all negative first, then all positive).\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "metadata": {
        "id": "DWicQ4c582-_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get spread of classes in train\n",
        "unique, count = np.unique(y_train, return_counts=True)\n",
        "print(unique)\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYQRBisg9oTc",
        "outputId": "13ca242b-d8ce-4ffd-bd29-d6abe2750469"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4]\n",
            "[324 236 260 324 236]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating simple model without pretrain"
      ],
      "metadata": {
        "id": "coNvG8tRGLkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 64, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoYEwAB8GQpN",
        "outputId": "6b8c118b-0508-42d3-bf8a-46b96acca6c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 64)           640000    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                204832    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 845,445\n",
            "Trainable params: 845,445\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PRhhjTqaEq7",
        "outputId": "c48e1b07-bce0-4d87-9215-c793bea856fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1380, 100) (345, 100)\n",
            "(1380,) (345,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fit data in model and check validation accuracy"
      ],
      "metadata": {
        "id": "ntPQhFcn3oiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_P82BapHCN6",
        "outputId": "6f215ebd-8152-43e1-e50d-065d995168ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 4s 9ms/step - loss: 1.5512 - acc: 0.3232 - val_loss: 1.3848 - val_acc: 0.5072\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.0178 - acc: 0.7449 - val_loss: 0.8579 - val_acc: 0.7507\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 0.2648 - acc: 0.9942 - val_loss: 0.3806 - val_acc: 0.8957\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9217\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9246\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.4366e-04 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9304\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.2683e-05 - acc: 1.0000 - val_loss: 0.1956 - val_acc: 0.9275\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.5561e-06 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9420\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.8705e-07 - acc: 1.0000 - val_loss: 0.2098 - val_acc: 0.9304\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 7.0230e-08 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.9420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plotting training and validation accuracy"
      ],
      "metadata": {
        "id": "5UbR23Hn3vWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oVDEspIIli3L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "2e09178b-b63b-42e4-cdcb-95cf59e72a1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Test Data"
      ],
      "metadata": {
        "id": "65bMfBBRIHu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = os.path.join(new_base_dir, 'test')\n",
        "\n",
        "test_labels = []\n",
        "test_data = []\n",
        "\n",
        "for label_type in ['business', 'entertainment','politics', 'sport', 'tech']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in os.listdir(dir_name):\n",
        "        if fname[-4:] == '.txt':       \n",
        "            f = open(os.path.join(dir_name, fname))        \n",
        "            a = remove_stopwords(f.read()) # removing stopwords\n",
        "            a = a.translate(remove_digits) # removing digits\n",
        "            a = a.translate(str.maketrans('', '', string.punctuation)) # removing punctuation  \n",
        "            test_data.append(a)\n",
        "            f.close()\n",
        "            if label_type == 'business':\n",
        "                test_labels.append(0)\n",
        "            elif label_type == 'entertainment':\n",
        "                test_labels.append(1)\n",
        "            elif label_type == 'politics':\n",
        "                test_labels.append(2)\n",
        "            elif label_type == 'sport':\n",
        "                test_labels.append(3)    \n",
        "            else:\n",
        "                test_labels.append(4)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(test_data)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_test = np.asarray(test_labels)"
      ],
      "metadata": {
        "id": "VjPPq29-IvPm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "id": "91QvdlRbsoaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f295b13a-d168-4e00-9ecb-ae5f730b8c62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluating model on test data"
      ],
      "metadata": {
        "id": "l95L7iZW31W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "l9okolDfJqua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbda9fe-c949-42c7-ac7a-e0572ba396d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1582 - acc: 0.9500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1582261025905609, 0.949999988079071]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Accuracy = 92%"
      ],
      "metadata": {
        "id": "wGXr3TxtKBrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using pretrained Glove Model"
      ],
      "metadata": {
        "id": "hXjkfqHHJT8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "M-04ZKvnli3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ecb705b-b40b-432e-b413-6b9bdfc5c4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "glove_dir = '/content/drive/MyDrive/Colab Notebooks/glove.6B'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_index)"
      ],
      "metadata": {
        "id": "tzFYHeRurWXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc83cc0-1b71-47fb-e6e6-a859e67fdf64"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28180"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "id": "lDsXi2oqli3K"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix[2000]"
      ],
      "metadata": {
        "id": "tfMoa0DYwWqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6823969b-4566-4517-bc7b-2a3872b1d651"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.39243001, -0.021736  , -0.086949  ,  0.18288   , -0.10802   ,\n",
              "       -0.32512   , -0.33881   ,  0.28652999,  0.11288   , -0.20399   ,\n",
              "        0.25962999,  0.8003    ,  0.072678  ,  0.61192   ,  0.01557   ,\n",
              "       -0.74147999, -0.074433  ,  0.25951001,  0.43291   ,  0.19305   ,\n",
              "       -0.75418001,  0.11783   , -0.23720001,  0.99037999, -0.36273   ,\n",
              "       -0.64504999, -0.56847   , -0.62812001, -0.50446999, -0.38536   ,\n",
              "        0.84289998,  0.18189   , -0.45210001, -0.38490999, -0.36796001,\n",
              "        0.42899999,  0.24612001,  0.11744   , -0.46342999, -0.38428   ,\n",
              "        0.22799   ,  0.069995  , -0.11054   ,  0.40669999, -0.19937   ,\n",
              "       -0.47464001, -0.37696001, -0.66829997,  0.032884  , -0.59792   ,\n",
              "       -0.14269   ,  0.15245   ,  0.26383001,  0.7069    ,  0.093431  ,\n",
              "       -0.60867   ,  0.19171999, -1.26300001,  2.11129999,  0.55993003,\n",
              "        0.30873001, -0.39096001, -0.058056  , -0.39776   ,  0.66377002,\n",
              "       -0.27748999,  0.21975   ,  0.39133999,  1.18009996, -0.96605003,\n",
              "       -0.22015999, -0.56181997, -0.25003999,  0.26526001,  0.44709   ,\n",
              "        0.19467001,  0.072357  ,  0.22754   , -0.90083998,  0.30085999,\n",
              "        1.22669995,  0.54679   ,  0.15347999, -1.15030003, -1.6494    ,\n",
              "       -0.32097   , -0.18116   , -0.05704   , -0.46972001, -0.45139   ,\n",
              "       -0.8193    ,  0.12885   , -0.24777   , -0.64358002, -0.063122  ,\n",
              "       -0.21528   ,  1.13139999,  0.90091002,  0.99232   , -1.02900004])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FJX3LQKVli3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df32d977-2cfa-4103-c535-0f2122233658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10000)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                320032    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,320,645\n",
            "Trainable params: 1,320,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "glove_model = Sequential()\n",
        "glove_model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "glove_model.add(Flatten())\n",
        "glove_model.add(Dense(32, activation='relu'))\n",
        "glove_model.add(Dense(16, activation='relu'))\n",
        "glove_model.add(Dense(5, activation='softmax'))\n",
        "glove_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "3JN_TvkPli3L"
      },
      "outputs": [],
      "source": [
        "glove_model.layers[0].set_weights([embedding_matrix])\n",
        "glove_model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_val.shape)\n",
        "print(y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "xyd4G18YD5Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4fddf6-56fb-45fc-9656-70fc7ea2b913"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1380, 100) (345, 100)\n",
            "(1380,) (345,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cuLjrNE3li3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2906fc5e-5744-4137-885a-890ad0950bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 1s 7ms/step - loss: 0.8165 - accuracy: 0.7007 - val_loss: 0.3046 - val_accuracy: 0.8899\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9717 - val_loss: 0.2653 - val_accuracy: 0.9014\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9978 - val_loss: 0.2416 - val_accuracy: 0.9072\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.2937 - val_accuracy: 0.9043\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9072\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9072\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9130\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9072\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9072\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9072\n"
          ]
        }
      ],
      "source": [
        "glove_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = glove_model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "glove_model.save_weights('pre_trained_glove_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "vIBJZsI6LAk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f0284a-535d-494b-8116-6ad72e001554"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18780013918876648, 0.9440000057220459]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Using Glove Pretrained Model, Test Accuracy = 93.20%"
      ],
      "metadata": {
        "id": "vhZG6pnbLKYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using FastText vectorizer"
      ],
      "metadata": {
        "id": "ZH43Lhdz4aMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs"
      ],
      "metadata": {
        "id": "AZEMsz4iKXJ1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#load embeddings\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('/content/drive/MyDrive/Colab Notebooks/wiki.simple.vec', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))\n",
        "\n",
        "\n",
        "\n",
        "#embedding matrix\n",
        "MAX_NB_WORDS = 10000\n",
        "embed_dim = 300\n",
        "\n",
        "print('preparing embedding matrix...')\n",
        "words_not_found = []\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDaahlGKXpE",
        "outputId": "0012a5a5-70e4-441d-cc8b-a2cd035a357b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "111052it [00:10, 10288.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found 111052 word vectors\n",
            "preparing embedding matrix...\n",
            "number of null word embeddings: 813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_model = Sequential()\n",
        "fast_model.add(Embedding(nb_words, embed_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "fast_model.add(Flatten())\n",
        "\n",
        "fast_model.add(Dense(16, activation='relu'))\n",
        "fast_model.add(Dense(32, activation='relu'))\n",
        "fast_model.add(Dense(5, activation='softmax'))\n",
        "fast_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlTxFHbFKXrc",
        "outputId": "bd8e2d2d-2118-4f2f-8017-dcaa31122780"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 300)          3000000   \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                480016    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,480,725\n",
            "Trainable params: 480,725\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_model.layers[0].set_weights([embedding_matrix])\n",
        "fast_model.layers[0].trainable = False\n",
        "fast_model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "N5MdyqIRKXt2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "id": "TuO2i2pupxJz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_data.shape(), train_labels.shape())\n",
        "# print(test_data.shape(), test_labels.shape())\n",
        "type(x_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry35pMLzGN4L",
        "outputId": "76d2a06b-b148-422e-9b00-4f6598316802"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1380, 100)\n",
            "(1380,)\n",
            "(345, 100)\n",
            "(345,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "fast_model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=6,\n",
        "                    batch_size=32\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCWSPXyyL4Ga",
        "outputId": "c24557e4-774c-4e87-9017-9d94678b9409"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "44/44 [==============================] - 41s 942ms/step - loss: 0.1073 - accuracy: 0.9623 - val_loss: 2.5330 - val_accuracy: 0.2087\n",
            "Epoch 2/6\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 0.1085 - accuracy: 0.9587 - val_loss: 2.9563 - val_accuracy: 0.2000\n",
            "Epoch 3/6\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 0.1198 - accuracy: 0.9616 - val_loss: 2.5889 - val_accuracy: 0.2551\n",
            "Epoch 4/6\n",
            "44/44 [==============================] - 2s 52ms/step - loss: 0.0966 - accuracy: 0.9659 - val_loss: 2.7928 - val_accuracy: 0.2928\n",
            "Epoch 5/6\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 0.0918 - accuracy: 0.9645 - val_loss: 2.6755 - val_accuracy: 0.2174\n",
            "Epoch 6/6\n",
            "44/44 [==============================] - 2s 37ms/step - loss: 0.0906 - accuracy: 0.9616 - val_loss: 2.5609 - val_accuracy: 0.2493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f0df6f050>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3zVCsloFKt7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNGd_jJKh3Z",
        "outputId": "9a0abba5-160e-4761-b0ca-9a4cfcced374"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test1 = x_test[:345, :]"
      ],
      "metadata": {
        "id": "-iQQ6oGrKvPo"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiJao00HK5V3",
        "outputId": "443cade5-630e-410a-a497-c96cc599d3ab"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(345, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk5gKBtBKhzq",
        "outputId": "7bb3fe71-918f-44bf-bc53-8366523ddf6a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(345,)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fast_model.evaluate(x_test1, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZUBprmSKXwW",
        "outputId": "76fdc323-36d4-4e30-b1f6-b6771e3c83e7"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 11ms/step - loss: 2.7816 - accuracy: 0.1768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.781627655029297, 0.1768115907907486]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification using word2vec vectorizer"
      ],
      "metadata": {
        "id": "VfhK6SuY4hkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import warnings\n",
        "\n",
        "\n",
        "data_tuples = list(zip(train_data,train_labels))\n",
        "df = pd.DataFrame(data_tuples, columns=['News','Label'])\n",
        "\n",
        "vec_model = Word2Vec(df, min_count=1)\n",
        "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n",
        "\n",
        "class Vectorizer(object):\n",
        "    \n",
        "    def __init__(self, vec):\n",
        "        self.vec = vec\n",
        "        self.dim = len(vec.values())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
        "\n",
        "class Classifier(object):\n",
        "    \n",
        "    def __init__(self, model, param):\n",
        "        self.model = model\n",
        "        self.param = param\n",
        "        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n",
        "\n",
        "    def fit(self, X, y):        \n",
        "        return self.gs.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.gs.predict(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['News'], df['Label'], test_size=0.2, shuffle=True)\n",
        "clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', model)])\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "MP5PtbdqLApD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40c2241-d7e0-44ee-c390-692a68e88b5a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 4ms/step - loss: 2.1608 - acc: 0.2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove Model with LSTM "
      ],
      "metadata": {
        "id": "PB9bBcXpLpQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM\n",
        "glove_model = Sequential()\n",
        "glove_model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "# glove_model.add(LSTM(16))\n",
        "glove_model.add(LSTM(32))\n",
        "glove_model.add(Dense(5, activation='softmax'))\n",
        "glove_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmsmRsnCLtBF",
        "outputId": "bb44192c-71c5-4cb8-aa31-e68002abed1b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 100, 100)          1000000   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 32)                17024     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,017,189\n",
            "Trainable params: 1,017,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUVqIzKQOH4O",
        "outputId": "5c1c50b1-e0e9-482b-f986-848dc24a780c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(glove_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo1LSL8TPEEJ",
        "outputId": "f0e3d786-f751-4adc-b7d2-88ab6fe98dc7"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_model.layers[0].set_weights([embedding_matrix])\n",
        "# glove_model.layers[0].trainable = False\n",
        "\n",
        "glove_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "history = glove_model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "glove_model.save_weights('pre_trained_glove_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyNAlK4dLtJR",
        "outputId": "4c668d9e-3f5e-438a-b23e-5ab9d1f294ba"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 2s 36ms/step - loss: 1.6047 - accuracy: 0.2326 - val_loss: 1.5960 - val_accuracy: 0.2464\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 2s 39ms/step - loss: 1.5193 - accuracy: 0.3449 - val_loss: 1.6015 - val_accuracy: 0.2319\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 2s 39ms/step - loss: 1.1468 - accuracy: 0.6949 - val_loss: 1.7609 - val_accuracy: 0.2116\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 0.6700 - accuracy: 0.8797 - val_loss: 2.0010 - val_accuracy: 0.2058\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 1s 32ms/step - loss: 0.3755 - accuracy: 0.9471 - val_loss: 2.1908 - val_accuracy: 0.2203\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 0.2200 - accuracy: 0.9522 - val_loss: 2.4855 - val_accuracy: 0.2116\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.1589 - accuracy: 0.9580 - val_loss: 2.6047 - val_accuracy: 0.1942\n",
            "Epoch 8/10\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.1410 - accuracy: 0.9580 - val_loss: 2.6794 - val_accuracy: 0.2290\n",
            "Epoch 9/10\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.1263 - accuracy: 0.9594 - val_loss: 2.6936 - val_accuracy: 0.2145\n",
            "Epoch 10/10\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.1069 - accuracy: 0.9587 - val_loss: 2.8107 - val_accuracy: 0.2435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ6H5-QWMmee",
        "outputId": "15115c28-d0b9-46be-9838-b38f592b65b1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 14ms/step - loss: 2.9976 - accuracy: 0.1884\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.997629404067993, 0.18840579688549042]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FastText Model with LSTM "
      ],
      "metadata": {
        "id": "tfhF5WtsLuLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fast_model = Sequential()\n",
        "fast_model.add(Embedding(nb_words, embed_dim,\n",
        "          weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "# fast_model.add(Flatten())\n",
        "fast_model.add(LSTM(32))\n",
        "fast_model.add(Dense(5, activation='softmax'))\n",
        "fast_model.summary()\n",
        "\n",
        "\n",
        "fast_model.layers[0].set_weights([embedding_matrix])\n",
        "fast_model.layers[0].trainable = False\n",
        "fast_model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "fast_model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=6,\n",
        "                    batch_size=32\n",
        "                    )\n",
        "\n",
        "\n",
        "fast_model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zthXJo1VLyWh",
        "outputId": "d25f1bf4-fae0-4610-9a75-b0e3a160af83"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 100, 300)          3000000   \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 32)                42624     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,042,789\n",
            "Trainable params: 42,789\n",
            "Non-trainable params: 3,000,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 1.6106 - accuracy: 0.2355 - val_loss: 1.5773 - val_accuracy: 0.3072\n",
            "Epoch 2/6\n",
            "44/44 [==============================] - 2s 37ms/step - loss: 1.5748 - accuracy: 0.2674 - val_loss: 1.5852 - val_accuracy: 0.2870\n",
            "Epoch 3/6\n",
            "44/44 [==============================] - 2s 38ms/step - loss: 1.5456 - accuracy: 0.3174 - val_loss: 1.5901 - val_accuracy: 0.2957\n",
            "Epoch 4/6\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 1.5039 - accuracy: 0.3457 - val_loss: 1.6072 - val_accuracy: 0.3101\n",
            "Epoch 5/6\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 1.4510 - accuracy: 0.3746 - val_loss: 1.6561 - val_accuracy: 0.2029\n",
            "Epoch 6/6\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 1.3667 - accuracy: 0.4522 - val_loss: 1.7745 - val_accuracy: 0.1362\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 1.7291 - accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7290637493133545, 0.20000000298023224]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec Model with LSTM "
      ],
      "metadata": {
        "id": "zlTZ1_E1LzfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import warnings\n",
        "\n",
        "\n",
        "data_tuples = list(zip(train_data,train_labels))\n",
        "df = pd.DataFrame(data_tuples, columns=['News','Label'])\n",
        "\n",
        "vec_model = Word2Vec(df, min_count=1)\n",
        "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n",
        "\n",
        "class Vectorizer(object):\n",
        "    \n",
        "    def __init__(self, vec):\n",
        "        self.vec = vec\n",
        "        self.dim = len(vec.values())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
        "\n",
        "class Classifier(object):\n",
        "    \n",
        "    def __init__(self, model, param):\n",
        "        self.model = model\n",
        "        self.param = param\n",
        "        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n",
        "\n",
        "    def fit(self, X, y):        \n",
        "        return self.gs.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.gs.predict(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['News'], df['Label'], test_size=0.2, shuffle=True)\n",
        "model.add(Embedding(nb_words, embed_dim,\n",
        "           input_length=maxlen, trainable=False))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', model)])\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ac9KJrRc2z",
        "outputId": "b2ea4baf-4894-4584-9f26-5e8789f4be2d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 64)           640000    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                204832    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            " embedding_17 (Embedding)    (None, 5, 300)            3000000   \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 32)                42624     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            " embedding_18 (Embedding)    (None, 5, 300)            3000000   \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 32)                42624     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,931,023\n",
            "Trainable params: 931,023\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            " 1/44 [..............................] - ETA: 1s - loss: 1.5962 - acc: 0.3125WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            " 3/44 [=>............................] - ETA: 1s - loss: 1.5983 - acc: 0.2292WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            " 5/44 [==>...........................] - ETA: 1s - loss: 1.6050 - acc: 0.2250WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            " 7/44 [===>..........................] - ETA: 1s - loss: 1.6098 - acc: 0.2366WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            " 9/44 [=====>........................] - ETA: 1s - loss: 1.6029 - acc: 0.2604WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "11/44 [======>.......................] - ETA: 1s - loss: 1.6023 - acc: 0.2557WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "13/44 [=======>......................] - ETA: 1s - loss: 1.6027 - acc: 0.2524WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "15/44 [=========>....................] - ETA: 1s - loss: 1.6051 - acc: 0.2458WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "17/44 [==========>...................] - ETA: 1s - loss: 1.6058 - acc: 0.2426WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "19/44 [===========>..................] - ETA: 0s - loss: 1.6056 - acc: 0.2368WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "21/44 [=============>................] - ETA: 0s - loss: 1.6054 - acc: 0.2366WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "23/44 [==============>...............] - ETA: 0s - loss: 1.6051 - acc: 0.2418WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "25/44 [================>.............] - ETA: 0s - loss: 1.6044 - acc: 0.2438WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "27/44 [=================>............] - ETA: 0s - loss: 1.6025 - acc: 0.2454WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "29/44 [==================>...........] - ETA: 0s - loss: 1.6012 - acc: 0.2478WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "31/44 [====================>.........] - ETA: 0s - loss: 1.5999 - acc: 0.2510WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "33/44 [=====================>........] - ETA: 0s - loss: 1.6019 - acc: 0.2462WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "35/44 [======================>.......] - ETA: 0s - loss: 1.6018 - acc: 0.2464WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "37/44 [========================>.....] - ETA: 0s - loss: 1.6013 - acc: 0.2475WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "39/44 [=========================>....] - ETA: 0s - loss: 1.5996 - acc: 0.2524WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "41/44 [==========================>...] - ETA: 0s - loss: 1.5990 - acc: 0.2508WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "43/44 [============================>.] - ETA: 0s - loss: 1.6006 - acc: 0.2464WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'lstm_17/lstm_cell_17/kernel:0', 'lstm_17/lstm_cell_17/recurrent_kernel:0', 'lstm_17/lstm_cell_17/bias:0', 'dense_19/kernel:0', 'dense_19/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "44/44 [==============================] - 2s 38ms/step - loss: 1.6006 - acc: 0.2464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracies of different models\n",
        "\n",
        "# Simple model without pretrain = 92%\n",
        "\n",
        "# With Glove pretrain = 93.20%\n",
        "\n",
        "\n",
        "# With FastText Pretrained = 24%\n",
        "\n",
        "# With Word2Vec Pretrained = 20%\n",
        "\n",
        "\n",
        "# Glove model with LSTM = 24 %# \n",
        "\n",
        "# FastText model with LSTM = 18%\n",
        "\n",
        "# Word2Vec model with LSTM = 30%\n",
        "\n"
      ],
      "metadata": {
        "id": "R058tzp-UKZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here after the results Pretrained glove model is giving best accuracty in my case"
      ],
      "metadata": {
        "id": "fF46PNTIUbH8"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "ML_Assignment_05_021-19-0029.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}